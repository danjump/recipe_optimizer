{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CODE WALKTHROUGH\n",
    "\n",
    "(written by Max Candocia)\n",
    "\n",
    "The main code is found in `linear_modprog_solution.py`, but the general usage of the functions will be shown here.  See the Python file for more details on the inner workings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import linear_modprog_solution as lms\n",
    "import numpy\n",
    "import sqlite3\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LassoLarsIC\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 different ingredients\n",
      "100 different recipes\n"
     ]
    }
   ],
   "source": [
    "data = lms.get_model_data('hummus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` is a length-4 list of 4 `numpy` arrays.  \n",
    "\n",
    "`data[0]` is the matrix of predictors, where each row is a recipe, and each column is a proportion of ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.27161998e-01   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.97348208e-01   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.16069575e-02   0.00000000e+00   8.11545519e-01 ...,   5.72855660e-03\n",
      "    0.00000000e+00   3.00749222e-03]\n",
      " ..., \n",
      " [  6.86771403e-01   0.00000000e+00   0.00000000e+00 ...,   3.52371166e-04\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  3.84252252e-01   0.00000000e+00   0.00000000e+00 ...,   5.71400054e-04\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  8.45475805e-02   0.00000000e+00   0.00000000e+00 ...,   7.19553877e-04\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data[1]` contains the response variable information, but first it needs to have a function applied to it to determine what value is being regressed on.  In this case, I chose `y = rating*log(1+number_of_ratings)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 47, 4.319149), (1, 18, 3.388889), (2, 584, 4.657534), (3, 16, 4.4375), (4, 169, 4.16568), (5, 12, 4.833333), (6, 74, 4.094594), (7, 4, 5.0), (8, 25, 4.2), (9, 149, 4.597315), (10, 7, 3.714286), (11, 94, 4.234043), (12, 17, 4.294117), (13, 7, 4.571429), (14, 10, 4.5), (15, 13, 4.461538), (16, 23, 4.173913), (17, 18, 4.333333), (18, 106, 4.566038), (19, 18, 4.555555), (20, 4, 2.75), (21, 4, 3.75), (22, 625, 4.6704), (23, 7, 4.285714), (24, 2, 4.0), (25, 70, 4.3), (26, 3, 3.666667), (27, 45, 4.622222), (28, 26, 4.846154), (29, 13, 4.153846), (30, 6, 4.0), (31, 3, 5.0), (32, 43, 4.023256), (33, 25, 3.6), (34, 3, 4.666667), (35, 98, 4.612245), (36, 2, 4.5), (37, 29, 4.448276), (38, 112, 4.276786), (39, 1, 5.0), (40, 6, 4.666667), (41, 18, 4.055555), (42, 26, 4.461538), (43, 21, 2.809524), (44, 231, 4.554112), (45, 38, 4.131579), (46, 10, 4.9), (47, 1, 5.0), (48, 2, 4.5), (49, 72, 3.986111), (50, 27, 4.037037), (51, 2, 5.0), (52, 5, 4.6), (53, 9, 4.555555), (54, 872, 4.552752), (55, 241, 4.593361), (56, 17, 4.764706), (57, 3, 4.0), (58, 315, 4.377778), (59, 217, 4.682028), (60, 51, 4.627451), (61, 5, 4.2), (62, 10, 4.1), (63, 1, 5.0), (64, 1, 5.0), (65, 8, 4.0), (66, 26, 4.423077), (67, 75, 3.986667), (68, 11, 4.909091), (69, 568, 4.304577), (70, 22, 4.727273), (71, 27, 3.518518), (72, 9, 4.444445), (73, 6, 3.5), (74, 1918, 4.543274), (75, 98, 4.510204), (76, 18, 4.555555), (77, 2, 4.0), (78, 6, 3.833333), (79, 93, 4.430108), (80, 58, 4.793103), (81, 8, 3.875), (82, 59, 4.305085), (83, 9, 3.888889), (84, 34, 4.529412), (85, 1, 5.0), (86, 35, 4.314286), (87, 13, 4.615385), (88, 7, 4.571429), (89, 53, 3.943396), (90, 2, 4.5), (91, 59, 4.169491), (92, 16, 4.25), (93, 3, 4.666667), (94, 23, 4.0), (95, 310, 4.293549), (96, 42, 4.333333), (97, 52, 4.115385), (98, 33, 4.30303), (99, 10, 4.3)]\n",
      "APPLYING RESPONSE FUNCTION\n",
      "Data is now at 72 rows\n",
      "[  9.97837687  12.57238421  21.39409283   8.04718956  23.0354688\n",
      "   7.72364061  19.28131058  12.4115945    9.50601937  13.2649202\n",
      "  21.33631403  13.41355371   4.42595426   6.03539217  30.07434197\n",
      "   8.91189173   4.39444915   5.08307979   6.93147181  15.22476365\n",
      "  11.72914754   6.46937415  21.19381855   4.9437553   20.21802604\n",
      "  14.70450142   8.68435796  15.13629436  11.74968684   3.4657359\n",
      "   4.9437553   17.10224757  13.4522329    5.49306144   8.24209356\n",
      "  30.83094315  25.21267248   5.54517744  25.19736164  25.21035665\n",
      "  18.2841867    9.83137062   3.4657359   14.57774024  17.26519169\n",
      "  12.19863287  27.30772181  11.72442155  10.2337128    6.81068552\n",
      "  34.34515011  20.72492793  13.41355371   7.45932159  20.12728656\n",
      "  19.54405695   8.51424524  17.62650136   8.95449784   3.4657359\n",
      "  15.46032559  12.18026561   9.50601937  15.73014373   4.9437553\n",
      "  17.0713328   12.04115671   6.46937415  12.71221532  24.64408212\n",
      "  16.29853258  10.31094967]\n"
     ]
    }
   ],
   "source": [
    "print data[1]\n",
    "print 'APPLYING RESPONSE FUNCTION'\n",
    "data = lms.apply_response_function(data)\n",
    "#remove recipes that do not use chickpeas, as they are not hummus\n",
    "data = lms.require_ingredient_bounds(data,'chickpeas',[0.2,1])\n",
    "print data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data[2]` contains the labels for the recipes, with the names extracted from the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Tofu_Hummus' u'Savory_Pumpkin_Hummus' u'Curried_Hummus' u'Tao_Hummus'\n",
      " u'Hollys_Hummus' u'Avocado_Lime_Hummus' u'Fusion_Hummus'\n",
      " u'Cilantro_Jalapeno_Hummus' u'Chef_Johns_Green_Hummus'\n",
      " u'Five_Pepper_Hummus' u'Sun_Dried_Tomato_Hummus' u'Sweet_Potato_Hummus'\n",
      " u'Quick_and_Easy_Hummus' u'Black_Olive_Hummus'\n",
      " u'Spiced_Sweet_Roasted_Red_Pepper_Hummus' u'Hummus_II'\n",
      " u'Erins_Jalapeno_Hummus' u'Yummy_Cilantro_Jalapeno_Hummus'\n",
      " u'Sesame_Seed_Oil_Hummus' u'Beetroot_Hummus' u'Cookie_Dough_Hummus'\n",
      " u'Decadent_Hummus' u'Authentic_Kicked_Up_Syrian_Hummus'\n",
      " u'Spicy_Jalapeno_Hummus' u'Spicy_Roasted_Red_Pepper_and_Feta_Hummus'\n",
      " u'Best_Hummus' u'Roasted_Eggplant_and_Garlic_Hummus' u'Hummus_IV'\n",
      " u'Simple_Spicy_Hummus' u'Hummus_Pancake_with_Mediterranean_Spice_Mix'\n",
      " u'Sweet_Potato_Hummus_2' u'Black_Bean_and_Chickpea_Hummus'\n",
      " u'Cucumber_Hummus' u'Thai_Hummus' u'Arugula_Hummus' u'Real_Hummus'\n",
      " u'Jalapeno_Hummus' u'Wasabi_and_Soy_Sauce_Hummus'\n",
      " u'Easy_Roasted_Red_Pepper_Hummus' u'Smoky_Chipotle_Hummus'\n",
      " u'Slaw_mmin_Wraps' u'Lemon_Garlic_Hummus_2' u'Purple_Fiddle_Hummus'\n",
      " u'Veggie_and_Cilantro_Hummus_Sandwiches' u'Basic_Hummus'\n",
      " u'Bruschetta_with_Hummus' u'Extra_Easy_Hummus' u'Creamy_Yogurt_Hummus'\n",
      " u'Michelles_Zesty_Hummus_like_Spread' u'Fiery_Five_Pepper_Hummus'\n",
      " u'Hummus_III' u'Easy_Red_Pepper_Hummus' u'Sweet_Potato_Hummus'\n",
      " u'Wendy_Jaes_Hummus' u'Spicy_Three_Pepper_Hummus' u'Super_Easy_Hummus'\n",
      " u'Nicoles_Garbanzo_Citrus_Spread' u'Hummus_I'\n",
      " u'Sun_dried_Tomato_and_Fennel_Seed_Hummus' u'Joes_Hummus_with_Pine_Nuts'\n",
      " u'Quick_and_Yummy_Hummus' u'5_Minute_Olive_Hummus'\n",
      " u'Chef_Johns_Green_Hummus' u'Robins_Best_Ever_Hummus'\n",
      " u'Garlicky_Lemony_Hummus' u'Basil_and_Pesto_Hummus' u'Traditional_Hummus'\n",
      " u'Zesty_Walnut_Hummus'\n",
      " u'Spinach_Artichoke_Hummus_with_Roasted_Red_Peppers' u'Easy_Hummus'\n",
      " u'Awesome_Red_Pepper_Hummus_Dip'\n",
      " u'Quick_Sun_Dried_Tomato_and_Basil_Hummus']\n"
     ]
    }
   ],
   "source": [
    "print data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data[3]` contains the labels for the ingredients; the first label is `OTHER`, which means any ingredient that did not appear at least 5 times among all recipes, although this value can be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'OTHER' u'water' u'black beans, drained' u'chickpeas' u'hummus'\n",
      " u'cilantro leaves' u'fresh jalapeno peppers' u'sesame seeds' u'tahini'\n",
      " u'garlic' u'chopped onion' u'parsley' u'chopped tomato' u'lemon, juiced'\n",
      " u'lemon juice' u'olive oil' u'sesame oil' u'extra-virgin olive oil'\n",
      " u'tahini' u'basil leaves' u'crumbled feta cheese' u'garlic powder'\n",
      " u'dried oregano' u'paprika' u'ground black pepper' u'cayenne pepper'\n",
      " u'salt' u'sea salt' u'cumin']\n"
     ]
    }
   ],
   "source": [
    "print data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used is a LASSO model, with AIC being used to determine the best coefficients (cross-validation may prove better if more ingredients are used). \n",
    "\n",
    "The advantage of LASSO is that it works well with higher dimensionalities, so we don't have to worry as much about error. \n",
    "\n",
    "The intercept is set to false, since the sum of all proportions in a recipe is equal to 1, and this linear dependence makes an intercept redundant (and harder to understand in the context of missing ingredients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'OTHER' u'9.12882432967']\n",
      " [u'water' u'5.03591492969']\n",
      " [u'black beans, drained' u'8.04554305525']\n",
      " [u'chickpeas' u'17.0343567283']\n",
      " [u'hummus' u'0.0']\n",
      " [u'cilantro leaves' u'0.0']\n",
      " [u'fresh jalapeno peppers' u'0.0']\n",
      " [u'sesame seeds' u'0.0']\n",
      " [u'tahini' u'0.0']\n",
      " [u'garlic' u'0.0']\n",
      " [u'chopped onion' u'0.0']\n",
      " [u'parsley' u'0.0']\n",
      " [u'chopped tomato' u'0.0']\n",
      " [u'lemon, juiced' u'0.0']\n",
      " [u'lemon juice' u'28.7455024042']\n",
      " [u'olive oil' u'-9.9290403217']\n",
      " [u'sesame oil' u'0.0']\n",
      " [u'extra-virgin olive oil' u'0.0']\n",
      " [u'tahini' u'32.7888045982']\n",
      " [u'basil leaves' u'0.0']\n",
      " [u'crumbled feta cheese' u'0.0']\n",
      " [u'garlic powder' u'0.0']\n",
      " [u'dried oregano' u'0.0']\n",
      " [u'paprika' u'0.0']\n",
      " [u'ground black pepper' u'0.0']\n",
      " [u'cayenne pepper' u'0.0']\n",
      " [u'salt' u'0.0']\n",
      " [u'sea salt' u'0.0']\n",
      " [u'cumin' u'0.0']]\n"
     ]
    }
   ],
   "source": [
    "xvar = data[0]\n",
    "yvar = data[1]\n",
    "model = LassoLarsIC(criterion='aic',fit_intercept = False)\n",
    "model.fit(xvar,yvar)\n",
    "params = model.coef_\n",
    "print numpy.column_stack((data[3],params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results so far show that lemon juice and tahini are the most important ingredients to have in generous quantities.  \n",
    "\n",
    "I am not sure why \"hummus\" is an ingredient, and I would remove recipes that include it to avoid logical recursion (especially since it is high), although during the (yet-to-be-done) linear programming optimization process, it can be simply fixed to zero.\n",
    "\n",
    "The \"OTHER\" ingredient is somewhat high, and I think that we can explore models with higher dimensionality that use a more restrictive version of LASSO.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LINEAR PROGRAMMING\n",
    "\n",
    "\n",
    "Linear programming can be used to solve the issue of \"what should the recipe be?\"\n",
    "\n",
    "Basically, there are 3 constraints on the recipe\n",
    "\n",
    "1. Sum of proportions has to equal 1\n",
    "\n",
    "2. Ingredients have to be within the bounds that they appear in the training data.  This can be weighted to exclude the most extreme bounds to avoid issues with \"problem\" recipes.\n",
    "\n",
    "3. If a recipe  uses substitute ingredients (ingredients with a highly negative correlation), then the sum of those two ingredients should fall within a certain bounds.  \n",
    "\n",
    "This problem is relatively simple to solve using sklearn's linear programming solver, which uses the simplex method.\n",
    "\n",
    "Below is how this is implemented in the context of the code I provided. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sol = lms.solve_linear_programming(data[0],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'OTHER' u'0.0']\n",
      " [u'water' u'0.0']\n",
      " [u'black beans, drained' u'0.0']\n",
      " [u'chickpeas' u'0.227927105997']\n",
      " [u'hummus' u'0.0']\n",
      " [u'cilantro leaves' u'0.0654455432809']\n",
      " [u'fresh jalapeno peppers' u'0.0512045222548']\n",
      " [u'sesame seeds' u'0.0248187865036']\n",
      " [u'tahini' u'0.225378996481']\n",
      " [u'garlic' u'0.0273072609132']\n",
      " [u'chopped onion' u'0.106647169527']\n",
      " [u'parsley' u'0.0166006428658']\n",
      " [u'chopped tomato' u'0.0187303575666']\n",
      " [u'lemon, juiced' u'0.101827267018']\n",
      " [u'lemon juice' u'0.0']\n",
      " [u'olive oil' u'0.134112347593']\n",
      " [u'sesame oil' u'0.0']\n",
      " [u'extra-virgin olive oil' u'0.0']\n",
      " [u'tahini' u'0.0']\n",
      " [u'basil leaves' u'0.0']\n",
      " [u'crumbled feta cheese' u'0.0']\n",
      " [u'garlic powder' u'0.0']\n",
      " [u'dried oregano' u'0.0']\n",
      " [u'paprika' u'0.0']\n",
      " [u'ground black pepper' u'0.0']\n",
      " [u'cayenne pepper' u'0.0']\n",
      " [u'salt' u'0.0']\n",
      " [u'sea salt' u'0.0']\n",
      " [u'cumin' u'0.0']]\n"
     ]
    }
   ],
   "source": [
    "vals = sol.values()[4]\n",
    "print numpy.column_stack([data[3],vals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this, we should have the following weight proportions for an ideal hummus recipe (by weight):\n",
    "\n",
    "* chickpeas: 22.8%\n",
    "* tahini: 22.5%\n",
    "* olive oil: 13.4%\n",
    "* chopped onion: 10.7%\n",
    "* lemon, juiced: 10.2%\n",
    "* cilantro leaves: 6.5%\n",
    "* jalepeno peppers: 5.1%\n",
    "* sesame seeds: 2.5%\n",
    "* garlic: 2.7%\n",
    "* chopped tomato: 1.9%\n",
    "\n",
    "This recipe looks like it could be decent.  Obviously the algorithm still needs to be refined, but this solution makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##CLUSTERING\n",
    "\n",
    "Clustering should be performed to remove outlier recipes and possibly group large branches of the training data separately in case there are different \"classes\" of recipes.  Hierarchical methods are appropriate for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
